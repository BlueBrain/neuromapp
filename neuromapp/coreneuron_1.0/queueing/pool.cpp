/*
 * Neuromapp - pool.cpp, Copyright (c), 2015,
 * Kai Langen - Swiss Federal Institute of technology in Lausanne,
 * kai.langen@epfl.ch,
 * All rights reserved.
 *
 * This program is free software; you can redistribute it and/or
 * modify it under the terms of the GNU General Public License
 * as published by the Free Software Foundation; either version 2
 * of the License, or (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 * You should have received a copy of the GNU Lesser General Public
 * License along with this library.
 */

/**
 * @file neuromapp/coreneuron_1.0/queueing/pool.cpp
 * \brief Contains pool class definition.
 */

#include <boost/array.hpp>
#include <stdio.h>
#include <stdlib.h>
#include <iostream>
#include <fstream>
#include <time.h>
#include <ctime>
#include <numeric>
#include <boost/range/algorithm/random_shuffle.hpp>
#include <boost/range/algorithm_ext/iota.hpp>
#include <boost/random/mersenne_twister.hpp>
#include <boost/random.hpp>

#include "coreneuron_1.0/queueing/pool.h"

namespace queueing {

pool::pool(int numCells,
int simTime, bool verbose, bool algebra,
int out, int in, int nc, int procs, int rank){
    num_cells_ = numCells;
    sim_time_ = static_cast<double>(simTime);
    std::cout<<simTime<<std::endl;
    v_ = verbose;
    perform_algebra_ = algebra;
    num_out_ = out;
    num_in_ = in;
    netcons_per_input_ = nc;
    num_procs_ = procs;
    rank_ = rank;
    spike_events_ = 0;
    total_received_ = 0;
    total_relevant_ = 0;

    thread_datas_.resize(num_cells_);
    create_presysns();
    nin_.resize(num_procs_);
    displ_.resize(num_procs_);
}

void pool::create_presyns(){
    //assign input and output gid's
    std::vector<int> available_inputs;
    std::vector<int> cellgroups;
    assert(num_cells_ > 2);
    if(num_procs_ > 1){
        for(int i = 0; i < (num_procs_ * num_out_); ++i){
            if(i >= (rank_ * num_out_) && i < ((rank_ * num_out_) + num_out_)){
                output_presyns_.push_back(i);
            }
            else{
                available_inputs.push_back(i);
            }
        }
        //create a randomly ordered list of input_presyns_
        assert(available_inputs.size() >= num_in_);

        //random presyn and netcon selection
        boost::mt19937 generator(time(NULL) + rank_);
        boost::uniform_int<> uni_dist;
        boost::variate_generator<boost::mt19937&, boost::uniform_int<> >
            randomNumber(generator, uni_dist);
        boost::random_shuffle(available_inputs, randomNumber);
        available_inputs.resize(num_in_);
        //create a vector of randomly ordered cellgroups
        cellgroups.resize(num_cells_);
        boost::iota(cellgroups, 0);

        //for each input presyn,
        //select N unique netcons to cell groups
        boost::random_shuffle(cellgroups, randomNumber);
        for(int i = 0; i < num_in_; ++i){
            int presyn = available_inputs[i];
            for(int j = 0; j < netcons_per_input_; ++j){
                input_presyns_[presyn].push_back(cellgroups[j]);
            }
        }
    }
    else{
        for(int i = 0; i < num_out_; ++i){
            output_presyns_.push_back(i);
        }
        assert(input_presyns_.empty());
    }
}

void pool::accumulate_stats(){
    int all_ite_received = 0;
    int all_enqueued = 0;
    int all_delivered = 0;
    for(int i=0; i < thread_datas_.size(); ++i){
        all_ite_received += thread_datas_[i].ite_received_;
        all_enqueued += thread_datas_[i].enqueued_;
        all_delivered += thread_datas_[i].delivered_;
    }

    if(v_){
        std::cout<<"Total inter-thread received: "<<all_ite_received<<std::endl;
        std::cout<<"Total enqueued: "<<all_enqueued<<std::endl;
        std::cout<<"Events generated by spikes: "<<spike_events_<<std::endl;
        std::cout<<"Total delivered: "<<all_delivered<<std::endl;
    }
    neuromapp_data.put_copy("inter_received", all_ite_received);
    neuromapp_data.put_copy("enqueued", all_enqueued);
    neuromapp_data.put_copy("spikes", spike_events_);
    neuromapp_data.put_copy("delivered", all_delivered);
}

double pool::send_events(int myID){
    int curTime = thread_datas_[myID].time_;
    while(generator_.empty(myID)) &&
    (generator_.compare_lte(myID, curTime)){
        gen_event g = generator_.pop(myID);
        event e = g.first;
        event_type type = g.second;
        assert(e.data_ < num_cells_);
        //if spike event send to spike_out
        switch(type){
            case SPIKE:
                spike_lock_.acquire();
                e.t_ += min_delay_;
                spikeout_.push_back(e);
                spike_lock_.release();
                break;
            case LOCAL:
            //if destination id is my own, self event, else ite
                thread_datas_[e.data_].self_send(e.data_, e.t_);
                break;
            case ITE:
                thread_datas_[e.data_].inter_thread_send(
                    e.data_, (e.t_ + min_delay_));
                break;
            default:
                std::cerr<<"error: invalid event type:"<<type<<std::endl;
                exit(EXIT_FAILURE);
        }
    }
    return generator_[myID].compare_lte(myID, curTime);
}

void pool::filter(){
    total_received_ += spikein_.size();
    std::map<int, std::vector<int> >::iterator it;
    event ev;
    for(int i = 0; i < spikein_.size(); ++i){
        it = input_presyns_.begin();
        ev = spikein_[i];
        it = input_presyns_.find(ev.data_);
        if(it != input_presyns_.end()){
            ++total_relevant_;
            for(size_t j = 0; j < it->second.size(); ++j){
                int dest = it->second[j];
                //send using non-mutex inter-thread send here
                thread_datas_[dest].inter_send_no_lock(dest, ev.t_);
                ++spike_events_;
            }
        }
    }
    spikeout_.clear();
    spikein_.clear();
}

//PARALLEL FUNCTIONS
void pool::fixed_step(){
    double top_time = 0;
    int curTime;
    #pragma omp parallel for schedule(static,1)
    for(int i = 0; i < num_cells_; ++i){
        for(int j = 0; j < num_cells_; ++j){
            curTime = thread_datas_[i].time_;
            if(top_time <= curTime){
                assert(curTime <= sim_time_);
                std::cout<<"sim time:"<<sim_time_<<" time: "<<curTime<<std::endl;
                top_time = send_events(i);
            }
            //Have threads enqueue their interThreadEvents
            thread_datas_[i].enqueue_my_events();

            if(perform_algebra_)
                thread_datas_[i].l_algebra(curTime);

            /// Deliver events
            while(thread_datas_[i].deliver(i, curTime));

            ++thread_datas_[i].time_;
        }
    }
}

}
