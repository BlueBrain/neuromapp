/*
 * Neuromapp - pool.cpp, Copyright (c), 2015,
 * Kai Langen - Swiss Federal Institute of technology in Lausanne,
 * kai.langen@epfl.ch,
 * All rights reserved.
 *
 * This program is free software; you can redistribute it and/or
 * modify it under the terms of the GNU General Public License
 * as published by the Free Software Foundation; either version 2
 * of the License, or (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 * You should have received a copy of the GNU Lesser General Public
 * License along with this library.
 */

/**
 * @file neuromapp/coreneuron_1.0/queueing/pool.cpp
 * \brief Contains pool class definition.
 */

#include <boost/array.hpp>
#include <stdio.h>
#include <stdlib.h>
#include <iostream>
#include <fstream>
#include <time.h>
#include <ctime>
#include <numeric>
#include <boost/range/algorithm/random_shuffle.hpp>
#include <boost/range/algorithm_ext/iota.hpp>
#include <boost/random/mersenne_twister.hpp>
#include <boost/random.hpp>

#include "coreneuron_1.0/queueing/pool.h"

namespace queueing {

pool::pool(){
    perform_algebra_ = algebra;
    thread_datas_.resize(num_cells_);
}

pool::~pool(){
    int all_ite_received = 0;
    int all_enqueued = 0;
    int all_delivered = 0;
    for(int i=0; i < thread_datas_.size(); ++i){
        all_ite_received += thread_datas_[i].ite_received_;
        all_enqueued += thread_datas_[i].enqueued_;
        all_delivered += thread_datas_[i].delivered_;
    }

    std::cout<<"Total inter-thread received: "<<all_ite_received<<std::endl;
    std::cout<<"Total enqueued: "<<all_enqueued<<std::endl;
    std::cout<<"Events generated by spikes: "<<spike_events_<<std::endl;
    std::cout<<"Total delivered: "<<all_delivered<<std::endl;

    neuromapp_data.put_copy("inter_received", all_ite_received);
    neuromapp_data.put_copy("enqueued", all_enqueued);
    neuromapp_data.put_copy("spikes", spike_events_);
    neuromapp_data.put_copy("delivered", all_delivered);
}

double pool::send_events(int myID){
    int curTime = thread_datas_[myID].time_;
    while(generator_.empty(myID)) &&
    (generator_.compare_lte(myID, curTime)){
        gen_event g = generator_.pop(myID);
        event e = g.first;
        event_type type = g.second;
        assert(e.data_ < num_cells_);
        //if spike event send to spike_out
        switch(type){
            case SPIKE:
                spike_lock_.acquire();
                e.t_ += min_delay_;
                spikeout_.push_back(e);
                spike_lock_.release();
                break;
            case LOCAL:
            //if destination id is my own, self event, else ite
                thread_datas_[e.data_].self_send(e.data_, e.t_);
                break;
            case ITE:
                thread_datas_[e.data_].inter_thread_send(
                    e.data_, (e.t_ + min_delay_));
                break;
            default:
                std::cerr<<"error: invalid event type:"<<type<<std::endl;
                exit(EXIT_FAILURE);
        }
    }
    return generator_[myID].compare_lte(myID, curTime);
}

void pool::filter(){
    total_received_ += spikein_.size();
    std::map<int, std::vector<int> >::iterator it;
    event ev;
    for(int i = 0; i < spikein_.size(); ++i){
        it = input_presyns_.begin();
        ev = spikein_[i];
        it = input_presyns_.find(ev.data_);
        if(it != input_presyns_.end()){
            ++total_relevant_;
            for(size_t j = 0; j < it->second.size(); ++j){
                int dest = it->second[j];
                //send using non-mutex inter-thread send here
                thread_datas_[dest].inter_send_no_lock(dest, ev.t_);
                ++spike_events_;
            }
        }
    }
    spikeout_.clear();
    spikein_.clear();
}

//PARALLEL FUNCTIONS
void pool::fixed_step(){
    double top_time = 0;
    int curTime;
    #pragma omp parallel for schedule(static,1)
    for(int i = 0; i < num_cells_; ++i){
        for(int j = 0; j < num_cells_; ++j){
            curTime = thread_datas_[i].time_;
            if(top_time <= curTime){
                assert(curTime <= sim_time_);
                std::cout<<"sim time:"<<sim_time_<<" time: "<<curTime<<std::endl;
                top_time = send_events(i);
            }
            //Have threads enqueue their interThreadEvents
            thread_datas_[i].enqueue_my_events();

            if(perform_algebra_)
                thread_datas_[i].l_algebra(curTime);

            /// Deliver events
            while(thread_datas_[i].deliver(i, curTime));

            ++thread_datas_[i].time_;
        }
    }
}

}
